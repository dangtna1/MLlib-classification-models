{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2caed1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# 1. Start Spark session\n",
    "spark = SparkSession.builder.appName(\"ModelTraining\").getOrCreate()\n",
    "\n",
    "# 2. Load data\n",
    "train_df = spark.read.csv(\"train_set.csv\", header=True, inferSchema=True)\n",
    "test_df = spark.read.csv(\"test_set.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcdbe0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.6626451466830516\n",
      "+--------------------+----------+----------+--------------------+\n",
      "|            features|TenYearCHD|prediction|         probability|\n",
      "+--------------------+----------+----------+--------------------+\n",
      "|(16,[0,1,2,7,8,9,...|         0|       1.0|[0.39640490073695...|\n",
      "|(16,[1,2,5,7,8,9,...|         0|       1.0|[0.34072652066599...|\n",
      "|(16,[0,1,2,7,8,9,...|         1|       1.0|[0.37401917567010...|\n",
      "|[1.0,-0.301586855...|         0|       1.0|[0.17318863776027...|\n",
      "|[1.0,0.5151064948...|         0|       0.0|[0.52081678073214...|\n",
      "|(16,[0,1,2,7,8,9,...|         0|       1.0|[0.38615563751711...|\n",
      "|[1.0,0.6317769734...|         0|       1.0|[0.46442068248917...|\n",
      "|(16,[1,2,7,8,9,10...|         0|       0.0|[0.63698235568789...|\n",
      "|(16,[1,2,7,8,9,10...|         0|       1.0|[0.40223385161777...|\n",
      "|[1.0,-0.418257333...|         0|       0.0|[0.58493670272350...|\n",
      "|(16,[1,2,7,8,9,10...|         1|       0.0|[0.70520468904405...|\n",
      "|[1.0,-1.351621162...|         0|       0.0|[0.61500808057419...|\n",
      "|(16,[1,2,7,8,9,10...|         0|       0.0|[0.55023858394647...|\n",
      "|(16,[1,2,5,7,8,9,...|         0|       1.0|[0.21368363674625...|\n",
      "|(16,[1,2,5,7,8,9,...|         0|       0.0|[0.67053995520851...|\n",
      "|(16,[1,2,7,8,9,10...|         1|       1.0|[0.32074476819021...|\n",
      "|(16,[0,1,2,7,8,9,...|         0|       0.0|[0.77878062854871...|\n",
      "|(16,[0,1,2,7,8,9,...|         0|       0.0|[0.70946811747708...|\n",
      "|(16,[0,1,2,7,8,9,...|         1|       0.0|[0.52344311237635...|\n",
      "|(16,[0,1,2,7,8,9,...|         0|       1.0|[0.24677460168011...|\n",
      "+--------------------+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Assemble features (you need to list your feature columns here)\n",
    "feature_cols = [col for col in train_df.columns if col != \"TenYearCHD\"]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# # 4. Model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"TenYearCHD\")\n",
    "\n",
    "# 5. Build a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# 6. Define hyperparameter grid\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.1, 1.0])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .build())\n",
    "\n",
    "# 7. Evaluator\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"TenYearCHD\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# 8. CrossValidator (grid search with CV)\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,   # 3-fold CV\n",
    "    parallelism=4 # how many models to train in parallel (based on your cluster resources)\n",
    ")\n",
    "\n",
    "# 9. Train model (with tuning)\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# 10. Pick best model\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# 11. Evaluate on test set\n",
    "predictions = best_model.transform(test_df)\n",
    "\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"Test AUC: {auc}\")\n",
    "\n",
    "# Optional: Show some predictions\n",
    "predictions.select(\"features\", \"TenYearCHD\", \"prediction\", \"probability\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c412d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6403301886792453\n",
      "Test Precision (Weighted): 0.789055268778925\n",
      "Test Recall (Weighted): 0.6403301886792453\n",
      "Test F1 Score (Weighted): 0.6891549582581097\n",
      "Test ROC AUC: 0.6034274563077487\n"
     ]
    }
   ],
   "source": [
    "y_test  = predictions.select(\"TenYearCHD\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = predictions.select(\"prediction\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "test_recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "test_f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# # Print metrics\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Precision (Weighted): {test_precision}\")\n",
    "print(f\"Test Recall (Weighted): {test_recall}\")\n",
    "print(f\"Test F1 Score (Weighted): {test_f1}\")\n",
    "print(f\"Test ROC AUC: {test_roc_auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
